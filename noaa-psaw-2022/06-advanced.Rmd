---
title: "Advanced sdmTMB"
subtitle: "NOAA PSAW Seminar Series"
author: ""
institute: ""
date: "March 9, 2022"
output:
  xaringan::moon_reader:
    css: ["xaringan-themer.css", "theme.css"]
    lib_dir: libs
    nature:
      highlightLines: true
      countIncrementalSlides: false
---

<!-- Build with: xaringan::inf_mr() -->

```{r preamble, include=FALSE, cache=FALSE}
source(here::here("noaa-psaw-2022/preamble.R"))
do.call(knitr::opts_chunk$set, knitr_opts)
```

```{r libs, include=FALSE}
library(dplyr)
library(sdmTMB)
library(ggplot2)
```

# Time-varying intercept

* Several ways in sdmTMB
  * random effects ` + (1|year)`
  * smooth, ` + s(year)`
  * or as random walk (here)

* Note: a `0` or `-1` in formula for suppressing global intercept

.small[
```{r echo = TRUE}
mesh <- make_mesh(pcod, xy_cols = c("X", "Y"), cutoff = 10)
fit <- sdmTMB(
  density ~ 0 + s(depth, k = 5), 
  time_varying = ~ 1, #<<
  data = pcod, mesh = mesh,
  time = "year",  
  family = tweedie(link = "log"),
  silent = FALSE # see progress
)
```
]

---

# Getting coefficients 

Return with 
```{r eval = FALSE}
summary(fit)
```

Or by digging into `$sd_report`

```{r eval = FALSE}
fit$sd_report$par.random
```
Look for the first elements named `b_rw_t`

---

# Other approaches to modeling time-varying intercept

```{r eval = FALSE}
density ~ s(depth) + s(year,k=7)
```

```{r eval = FALSE}
density ~ s(depth) + (1|year)
```

---

# These approaches are equivalent

* Estimates and SEs identical  

```{r echo=FALSE}
fit_sm <- sdmTMB(
  density ~ s(depth,k=5) + s(year,k=7), 
  data = pcod, mesh = mesh,
  time = "year",  
  family = tweedie(link = "log"),
  silent = FALSE # see progress
)
pcod$fyear = as.factor(pcod$year)
fit_re <- sdmTMB(
  density ~ s(depth,k=5) + (1|fyear), 
  data = pcod, mesh = mesh,
  time = "year",  
  family = tweedie(link = "log"),
  silent = FALSE # see progress
)
# just make predictions on avg depth / location
newdf = data.frame("depth"=mean(pcod$depth),
                   "X" = mean(pcod$X),
                   "Y" = mean(pcod$Y),
                   year = unique(pcod$year))
newdf$fyear = as.factor(newdf$year)

pred_fit <- predict(fit, newdata = newdf, se_fit=TRUE)
pred_fit$model = "RW"
pred_sm <- predict(fit_sm, newdata = newdf, se_fit=TRUE)
pred_sm$model = "Smooth"
pred_re <- predict(fit_re, newdata = newdf, se_fit=TRUE)
pred_re$model = "RE"
pred = rbind(pred_fit, pred_sm, pred_re)

ggplot(pred, aes(year, est, fill = model, col=model)) + 
  geom_ribbon(aes(ymin=est - 2*est_se,ymax=est + 2*est_se),alpha=0.3,
              col = NA) + 
  geom_line(alpha = 0.3)

```

---

<img src="images/spidey.jpeg" width="650px" class="center" /> 

* H/T Eric Pederson
---

# Time-varying coefficients

Time-varying (random walk) effect of depth:

* Intercept in this model NOT time-varying
```{r}
fit <- sdmTMB(
  density ~ 1, 
  time_varying = ~ 0 + depth_scaled + depth_scaled2,#<<
  data = pcod, mesh = mesh,
  time = "year",
  family = tweedie(link = "log"),
  spatial = "off",
  spatiotemporal = "ar1",
  silent = FALSE
)
```

---

# Time-varying coefficients

* Could also model this with 2D smooth  
  * Additional smooth complexity could be added 
```{r}
fit <- sdmTMB(
  density ~ s(depth_scaled, year), #<<
  data = pcod, mesh = mesh,
  time = "year",
  family = tweedie(link = "log"),
  spatial = "off",
  spatiotemporal = "ar1",
  silent = FALSE
)
```

See the vignette [Intro to modelling with sdmTMB](https://pbs-assess.github.io/sdmTMB/articles/basic-intro.html) for more details.

---

# Spatially varying coefficients (SVC)

Spatially varying effect of time:

```{r, eval=TRUE, warning=FALSE}
pcod$year_scaled <- as.numeric(scale(pcod$year))
fit <- sdmTMB(
  density ~ s(depth, k = 5) + year_scaled,
  spatial_varying = ~ 0 + year_scaled, 
  data = pcod, mesh = mesh, 
  time = "year",
  family = tweedie(link = "log"),
  spatiotemporal = "off"
)
```

See `zeta_s` in the output, which represents the coefficient varying in space. You'll want to ensure you set up your model such that it ballpark has a mean of 0 (e.g., by including it in `formula` too).

```{r plot-zeta}
qcs_grid$year_scaled <- (qcs_grid$year - mean(pcod$year)) / sd(pcod$year)
p <- predict(fit, newdata = subset(qcs_grid, year == 2011))
ggplot(p, aes(X, Y, fill = zeta_s)) + geom_raster() +
  scale_fill_gradient2()
```

See the vignette on [Fitting spatial trend models with sdmTMB](https://pbs-assess.github.io/sdmTMB/articles/spatial-trend-models.html) for more details.

---

# Random intercepts

We can use the same syntax (`1 | group`) as lme4 or glmmTMB to fit random intercepts:

```{r, eval=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
pcod$year_factor <- as.factor(pcod$year)
fit <- sdmTMB(
  density ~ s(depth, k = 5) + (1 | year_factor),
  data = pcod, mesh = mesh,
  time = "year",
  family = tweedie(link = "log")
)
```

---

# Breakpoint and theshold effects

```{r, eval=FALSE}
fit <- sdmTMB(
  present ~ 1 + breakpt(depth_scaled), 
  data = pcod, mesh = mesh,
  family = binomial(link = "logit")
)
```

```{r, eval=FALSE}
fit <- sdmTMB(
  present ~ 1 + logistic(depth_scaled), 
  data = pcod, mesh = mesh,
  family = binomial(link = "logit")
)
```

See the vignette on [Threshold modeling with sdmTMB](https://pbs-assess.github.io/sdmTMB/articles/threshold-models.html) for more details.

---

# Simulating data

## Simulating data from scratch

```{r}
predictor_dat <- expand.grid(
  X = seq(0, 1, length.out = 100), Y = seq(0, 1, length.out = 100)
)
mesh <- make_mesh(predictor_dat, xy_cols = c("X", "Y"), cutoff = 0.05)
sim_dat <- sdmTMB_simulate(
  formula = ~ 1,
  data = predictor_dat,
  mesh = mesh,
  family = poisson(link = "log"),
  range = 0.3,
  sigma_O = 0.4,
  seed = 1,
  B = 1 # B0 = intercept
)
head(sim_dat)

# sample 200 points for fitting:
set.seed(1)
sim_dat_obs <- sim_dat[sample(seq_len(nrow(sim_dat)), 200), ]
```

```{r plot-sim-dat}
ggplot(sim_dat, aes(X, Y)) +
  geom_raster(aes(fill = exp(eta))) + # mean without observation error
  geom_point(aes(size = observed), data = sim_dat_obs, pch = 21) +
  scale_fill_viridis_c() +
  scale_size_area() +
  coord_cartesian(expand = FALSE)
```

Fit to the simulated data:

```{r}
mesh <- make_mesh(sim_dat_obs, xy_cols = c("X", "Y"), cutoff = 0.05)
fit <- sdmTMB(
  observed ~ 1,
  data = sim_dat_obs,
  mesh = mesh,
  family = poisson()
)
```

See [`?sdmTMB_simulate`](https://pbs-assess.github.io/sdmTMB/reference/sdmTMB_simulate.html) for more details.

## Simulating from an existing fit

```{r sim, include=FALSE, eval=FALSE}
s <- simulate(fit, nsim = 500)
dim(s)
s[1:3,1:4]
```

``` r
s <- simulate(fit, nsim = 500)
dim(s)
#> [1] 969 500
s[1:3,1:4]
#>      [,1]     [,2]     [,3]     [,4]
#> [1,]    0 59.40310 83.20888  0.00000
#> [2,]    0 34.56408  0.00000 19.99839
#> [3,]    0  0.00000  0.00000  0.00000
```

Using those simulations to check DHARMa residuals:

```{r plot-dharma, warning=FALSE, results='hide'}
# dharma_residuals(s, fit)
# or with the pipe, %>%:
simulate(fit, nsim = 500) %>% 
  dharma_residuals(fit)
```

See the vignette on [Residual checking with sdmTMB](https://pbs-assess.github.io/sdmTMB/articles/residual-checking.html),  [`?simulate.sdmTMB`](https://pbs-assess.github.io/sdmTMB/reference/simulate.sdmTMB.html), and [`?dharma_residuals`](https://pbs-assess.github.io/sdmTMB/reference/dharma_residuals.html) for more details.

---

# Sampling from the joint precision matrix

We can take samples from the implied parameter distribution assuming an MVN covariance matrix on the internal parameterization:

```{r plot-mvn}
samps <- gather_sims(fit, nsim = 1000)
ggplot(samps, aes(.value)) + geom_histogram() +
  facet_wrap(~.variable, scales = "free_x")
```

See [`?gather_sims`](https://pbs-assess.github.io/sdmTMB/reference/gather_sims.html) and [`?get_index_sims`](https://pbs-assess.github.io/sdmTMB/reference/get_index_sims.html) for more details.

---

# Calculating uncertainty on spatial predictions

The fastest way to get point-wise prediction uncertainty is to use the MVN samples:

```{r plot-pred-mvn}
p <- predict(fit, newdata = predictor_dat, nsim = 500)
predictor_dat$se <- apply(p, 1, sd)
ggplot(predictor_dat, aes(X, Y, fill = se)) +
  geom_raster() +
  scale_fill_viridis_c(option = "A") +
  coord_cartesian(expand = FALSE)
```


# Priors

Priors/penalties can be placed on most parameters. For example, here we place a PC (penalized complexity) prior on the Matérn random field parameters, a standard normal prior on the effect of depth, a Normal(0, 10^2) prior on the intercept, and a half-normal prior on the Tweedie dispersion parameter (`phi`):

```{r priors}
mesh <- make_mesh(pcod, c("X", "Y"), cutoff = 10)
fit <- sdmTMB(
  density ~ depth_scaled,
  data = pcod, mesh = mesh,
  family = tweedie(),
  priors = sdmTMBpriors(
    matern_s = pc_matern(range_gt = 10, sigma_lt = 5),
    b = normal(c(0, 0), c(1, 10)),
    phi = halfnormal(0, 15)
  )
)
```

We can visualize the PC Matérn prior:

```{r plot-pc-matern}
plot_pc_matern(range_gt = 10, sigma_lt = 5)
```

See [`?sdmTMBpriors`](https://pbs-assess.github.io/sdmTMB/reference/priors.html) for more details.

---

# Bayesian MCMC sampling with Stan

The fitted model can be passed to the tmbstan package to sample from the posterior with Stan. Note this can be slow for large or poorly identified models. See examples of fixing parameters in [`?extract_mcmc`](https://pbs-assess.github.io/sdmTMB/reference/extract_mcmc.html).

```{r mcmc, warning=FALSE, message=FALSE, results='hide', eval=FALSE}
# only 1 chain and 400 iterations for speed:
fit_mcmc <- tmbstan::tmbstan(fit$tmb_obj, chains = 1, iter = 400)
```

Internal parameter posteriors:

``` r
print(fit_mcmc, pars = c("b_j", "omega_s[1]"))
#> Inference for Stan model: sdmTMB.
#> 1 chains, each with iter=400; warmup=200; thin=1; 
#> post-warmup draws per chain=200, total post-warmup draws=200.
#> 
#>             mean se_mean   sd  2.5%   25%   50%  75% 97.5% n_eff Rhat
#> b_j         0.99    0.03 0.15  0.62  0.93  1.00 1.06  1.27    35 1.00
#> omega_s[1] -0.07    0.03 0.23 -0.50 -0.23 -0.06 0.10  0.33    63 1.01
#> 
#> Samples were drawn using NUTS(diag_e).
#> For each parameter, n_eff is a crude measure of effective sample size,
#> and Rhat is the potential scale reduction factor on split chains (at 
#> convergence, Rhat=1).
```

Predicting with the Stan/tmbstan model:

``` r
pred_mcmc <- predict(fit, newdata = qcs_grid, tmbstan_model = fit_mcmc)
# Each row has 200 posterior samples for a row of the `newdata` data frame:
dim(pred_mcmc)
#> [1] 65826   200
```

See [`?extract_mcmc`](https://pbs-assess.github.io/sdmTMB/reference/extract_mcmc.html) for more details.

---

# Turning off random fields

We can turn off the random fields for model comparison:

```{r no-rf, warning=FALSE, message=FALSE}
fit_sdmTMB <- sdmTMB(
  present ~ poly(depth_scaled, 2),
  data = pcod, mesh = mesh,
  spatial = "off",
  family = binomial()
)
fit_glm <- glm(
  present ~ poly(depth_scaled, 2),
  data = pcod,
  family = binomial()
)

tidy(fit_sdmTMB)
broom::tidy(fit_glm)
```

---

# Using a custom INLA mesh

Defining a mesh directly with INLA:

```{r inla-mesh, warning=FALSE, fig.asp = 1, dpi = 40, out.width = "30%"}
bnd <- INLA::inla.nonconvex.hull(cbind(pcod$X, pcod$Y), convex = -0.1)
mesh_inla <- INLA::inla.mesh.2d(
  boundary = bnd,
  max.edge = c(25, 50)
)
mesh <- make_mesh(pcod, c("X", "Y"), mesh = mesh_inla)
plot(mesh)
```

```{r inla-mesh2, eval=FALSE}
fit <- sdmTMB(
  density ~ s(depth, k = 5),
  data = pcod, mesh = mesh,
  family = tweedie(link = "log")
)
```

---

# Barrier meshes

A barrier mesh limits correlation across barriers (e.g., land or water). See the example in [`?add_barrier_mesh`](https://pbs-assess.github.io/sdmTMB/reference/add_barrier_mesh.html).
