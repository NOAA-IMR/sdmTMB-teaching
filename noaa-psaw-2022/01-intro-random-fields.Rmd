---
title: "Introduction to sdmTMB"
subtitle: "NOAA PSAW Seminar Series"
author: ""
institute: ""
date: "2022-03-02"
output:
  xaringan::moon_reader:
    css: ["xaringan-themer.css", "theme.css"]
    lib_dir: libs
    nature:
      highlightLines: true
      countIncrementalSlides: false
---

<!-- Previous slides: https://www.dropbox.com/s/gu43n4gvqmo0uzy/sdmTMB-intro-2021.pdf?dl=1 -->

<!-- Build with: xaringan::inf_mr() -->

```{r preamble, include=FALSE, cache=FALSE}
source(here::here("noaa-psaw-2022/preamble.R"))
do.call(knitr::opts_chunk$set, knitr_opts)
```

```{r libs, include=FALSE}
library(dplyr)
library(sdmTMB)
library(ggplot2)
```

# Who we are

* Eric Ward, Northwest Fisheries Science Center (Seattle)
* Sean Anderson, Fisheries and Oceans Canada (Nanaimo)
* Lewis Barnett, Alaska Fisheries Science Center (Seattle) 
* Philina English, Fisheries and Oceans Canada (Nanaimo)

---

# Plan for the 2-session course

* Session 1 (March 3): describe models and walk through code with us

* Session 2 (March 10): have sdmTMB installed, run models and explore advanced features

* Each day, we have ~1.5–2 hours of content, and will plan to take a 10–15 minute break halfway through.

* Have questions? Use the chat, ask during our break, or at the end. Thanks!

---

# Resources

* sdmTMB GitHub repository:  
  <https://github.com/pbs-assess/sdmTMB>
  
* sdmTMB documentation:  
  <https://pbs-assess.github.io/sdmTMB/index.html>

*  New features to suggest? Bugs?  
  <https://github.com/pbs-assess/sdmTMB/issues>

---

class: center, middle, inverse

# Covariance functions & Gaussian processes for time series

---

# Gaussian processes 101

* Using Gaussian processes (GPs) to approximate underlying truth

```{r sim-gp, fig.asp=0.5}
x <- seq(1, 50)
d <- as.matrix(dist(x, diag = TRUE))
set.seed(123)
df <- data.frame(
  x = x,
  true = c(spam::rmvnorm(1, mu = 0, Sigma = 1 * exp(-0.05 * d)))
)
df$y <- rnorm(df$true, df$true, 0.1)

g1 <- ggplot(df, aes(x, y)) +
  geom_point(col = "red", alpha = 0.7) +
  theme_bw() +
  xlab("") +
  ylab("Observations")
g2 <- g1 + geom_line(aes(x, true))

# gridExtra::grid.arrange(g1, g2, ncol = 1)
print(g2)
```

<!-- * There are many approaches to modeling 'latent' dynamics. GPs are one of those, without constraints (e.g. stationarity in time, ARMA properties, etc) -->

---

# Gaussian processes 101

* Dynamics of $\textbf{y}_t$ (observations at time $t$) can be approximated with a Gaussian process if $E[\textbf{y}_t] \sim \mathrm{MVN}(\mu, \Sigma)$

* $\mu$ may be fixed (e.g., $\mu = 0$)

* $\Sigma$ contains many parameters. Instead of estimating them all, elements can be approximated by a covariance function:
  * $\Sigma_{i,j} = f(x_{i}, x_{j})$
  * 2–3 parameters instead of $n (n-1)/2$ parameters

* Which to choose? 

---

# Matérn covariance

* Flexible, can be exponential or Gaussian

```{r matern-plot}
x <- seq(from = 0, to = 1, length.out = 100)
df <- data.frame(
  x = rep(x, 4),
  "nu" = sort(rep(c(0.5, 1.5, 2.5, 10), 100))
)
df$row <- seq(1, nrow(df))
df <- dplyr::group_by(df, row) %>%
  dplyr::mutate(
    cov =
      rSPDE::matern.covariance(h = x, kappa = 5, nu = nu, sigma = 1)
  )
df$nu <- as.factor(df$nu)

ggplot(df, aes(x, cov, col = nu, group = nu)) +
  geom_line(size = 1.3, alpha = 0.8) +
  theme_bw() +
  xlab("Distance") +
  ylab("Covariance") +
  ggtitle("Matérn covariance") +
  guides(col = guide_legend(title = expression(nu))) +
  theme(text = element_text(size = 21)) +
  coord_cartesian(expand = FALSE)
```

---

# Predictive process models 

* High dimensional datasets may still be computationally challenging

* Gaussian process predictive process models:
  * Estimate values at a subset of locations in the time series
  *   'knots', 'vertices', or 'control points'
  * Use covariance function to interpolate from knots to locations of observations

---

# Predictive process models 

```{r show-gp, fig.height=4}
x <- seq(1, 50)
d <- as.matrix(dist(x, diag = TRUE))
set.seed(123)
df <- data.frame(
  x = x,
  true = c(spam::rmvnorm(1, mu = 0, Sigma = 1 * exp(-0.05 * d)))
)
df$y <- rnorm(df$true, df$true, 0.1)
g1 <- ggplot(df, aes(x, y)) +
  geom_point(col = "red", alpha = 0.7) +
  theme_bw() +
  xlab("") +
  ylab("Observations") +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "gp", k = 25))
g2 <- ggplot(df, aes(x, y)) +
  geom_point(col = "red", alpha = 0.7) +
  theme_bw() +
  xlab("") +
  ylab("Observations") +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "gp", k = 7))
gridExtra::grid.arrange(g1, g2, ncol = 1)
```

---

class: center, middle, inverse

# Spatial data & random fields

---

# Moving from 1 to 2 dimensions

Spatial data types:

* Lattice: gridded data, e.g. interpolated SST from satellite observations 

--

* Areal: data collected in neighboring spatial areas, e.g. commercial catch records by state / county

--

* Georeferenced: data where observations are associated with latitude and longitude 
  * Locations may be unique or repeated (stations)
---

# Why is space important? 

* Data covary spatially (data that are closer are more similar)

--

* Relationship between distance and covariance can be described with a spatial covariance function

--

* Covariance function in 2D may be
  * isotropic (same covariance in each direction)
  * anisotropic (different in each direction)

<!-- * Assumed stationary -->

---

# What is a random field?

```{r sim-rf-dat, message=FALSE, warning=FALSE}
predictor_dat <- expand.grid(
  x = seq(0, 1, length.out = 100),
  y = seq(0, 1, length.out = 100),
  year = seq_len(6)
)
mesh <- make_mesh(predictor_dat, xy_cols = c("x", "y"), cutoff = 0.05)
sim_dat <- sdmTMB_simulate(
  formula = ~1,
  data = predictor_dat,
  time = "year",
  mesh = mesh,
  family = gaussian(),
  range = 0.5,
  sigma_E = 0.2,
  phi = 0.1,
  sigma_O = NULL,
  seed = 1,
  B = 0
)
```

```{r random-field-demo}
ggplot(sim_dat, aes(x, y, fill = mu)) +
  facet_wrap(vars(year)) +
  geom_raster() +
  scale_fill_gradient2() +
  coord_fixed(expand = FALSE)
```

---
background-image: url("images/eagle.png")
background-position: bottom right
background-size: 35%

# Random field

<img src="images/rf-wikipedia.png" width="550px" />

---
background-image: url("images/beaker.png")
background-position: bottom right
background-size: 35%

# Random field

* A 2 dimensional "Gaussian Process"

--

* A realization from a multivariate normal distribution with some covariance function

---
background-image: url("images/elmo.png")
background-position: bottom right
background-size: 30%

# Random field

* A way of estimating a wiggly surface to account for spatial and/or spatiotemporal correlation in data.

--

* Alternatively, a way of estimating a wiggly surface to account for "latent" or unobserved variables.

--

* As a bonus, it provides useful covariance parameter estimates: spatial variance and the distance at data points are effectively uncorrelated ("range")

<!-- TODO: include nugget / sill? Show slide with semivariogram image? -->
---

# Many ways to simulate random fields in R

* `RandomFields::RFsimulate()` simulates univariate / multivariate fields
* `fields::sim.rf()` simulates random fields on a grid
* `geoR::grf()` simulates random fields with irregular observations
* `glmmfields::sim_glmmfields()` simulates random fields with/without extreme values
* `sdmTMB::sdmTMB_simulate()` simulates univariate fields with `sdmTMB`

???
Homework: try to work through some of these yourself. Make some plots, and see how changing the covariance affects the smoothness of these fields.
---

# Estimating random fields 

.small[
* Georeferenced data often involve 1000s or more points

* Like in the 1-D setting, we need to approximate the spatial field 
  * Options include nearest neighbor methods, covariance tapering, etc.

* sdmTMB uses an approach from INLA
  * for VAST users, this is the same
  * INLA books:  
    <https://www.r-inla.org/learnmore/books>
]

---

# INLA and the SPDE approach

.xsmall[
* SPDE: stochastic partial differential equation

* The solution to a specific SPDE is a Gaussian random field (GRF) with Matérn covariance

* This, and sparse precision matrices, let us efficiently fit approximations to GRFs to large spatial datasets

* INLA is software that performs data wrangling for SPDE estimation
  * INLA also performs approximate Bayesian estimation
  * sdmTMB uses INLA to wrangle matrices, but uses TMB for maximum likelihood estimation
]

.tiny[
Lindgren, F., Rue, H., and Lindström, J. 2011. An explicit link between Gaussian fields and Gaussian Markov random fields: the stochastic partial differential equation approach. Journal of the Royal Statistical Society: Series B. 73(4): 423–498.
]

---

# Introducing meshes

* Implementing the SPDE with INLA requires constructing a 'mesh'

```{r mesh-example, fig.width=6.5}
mesh <- make_mesh(pcod, xy_cols = c("X", "Y"), cutoff = 10)
ggplot() +
  inlabru::gg(mesh$mesh) +
  geom_point(data = pcod, aes(x = X, y = Y), alpha = 0.1, pch = 20) +
  coord_equal()
```

---

# Mesh construction

* A unique mesh is generally made for each dataset
* Rules of thumb:
  * More triangles = more computation time
  * Borders with coarser resolution reduce number of triangles
  * Use minimum edge size to avoid meshes becoming too fine
  * Want fewer vertices than data points

* "How to make a bad mesh?" [Haakon Bakka's book](https://haakonbakkagit.github.io/btopic114.html)

---

# Building your own mesh

* `INLA::inla.mesh.2d()`: lets many arguments be customized

* `INLA::meshbuilder()`: Shiny app for constructing a mesh, provides R code

* Meshes can include barriers / islands / coastlines with shapefiles

* INLA books
<https://www.r-inla.org/learnmore/books>
---

# Simplifying mesh construction in sdmTMB

* `make_mesh()` has 2 shortcuts to mesh construction

  1. K-means algorithm: used to cluster points (e.g., `n_knots = 100`); approach taken in VAST; sensitive to random `seed` argument!

  2. Cutoff: minimum allowed distance between vertices (e.g., `cutoff = 10`)
  
* Alternatively, build any INLA mesh and supply it to the `mesh` argument in `make_mesh()`.

---

# Example: cutoff = 10km

```{r mesh-example2, fig.width=6.5}
mesh <- make_mesh(pcod, xy_cols = c("X", "Y"), cutoff = 10)
ggplot() +
  inlabru::gg(mesh$mesh) +
  geom_point(data = pcod, aes(x = X, y = Y), alpha = 0.1, pch = 20) +
  coord_equal()
```

---
# Example: cutoff = 25km

```{r mesh-example3, fig.width=6.5}
mesh <- make_mesh(pcod, xy_cols = c("X", "Y"), cutoff = 25)
ggplot() +
  inlabru::gg(mesh$mesh) +
  geom_point(data = pcod, aes(x = X, y = Y), alpha = 0.1, pch = 20) +
  coord_equal()
```

---
# Example: cutoff = 50km

```{r mesh-example4, fig.width=6.5}
mesh <- make_mesh(pcod, xy_cols = c("X", "Y"), cutoff = 50)
ggplot() +
  inlabru::gg(mesh$mesh) +
  geom_point(data = pcod, aes(x = X, y = Y), alpha = 0.1, pch = 20) +
  coord_equal()
```

---

# Getting into UTMs

* Need a projection that preserves constant distance

* UTMs work well for regional analyses

* Helper function: `sdmTMB::add_utm_columns()`

* Internally, guesses at UTM zone and uses the sf package:
  * `sf::st_as_sf()`, `sf::st_transform()`, and `sf::st_coordinates()`

* Or use sp package

---
# Example of adding UTM columns

```{r, echo=TRUE, message=TRUE}
d <- data.frame(
  lat = c(52.1, 53.4), 
  lon = c(-130.0, -131.4)
)
d <- sdmTMB::add_utm_columns(d, c("lon", "lat"))
d
```

* Note default `units = "km"`
* Why? Range parameter estimated in units of X and Y
* Should be not too big or small for estimation
