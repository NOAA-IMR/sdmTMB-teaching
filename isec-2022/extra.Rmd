# Why sdmTMB

<img src="logo-sdmTMB.png" height="230px" class="centering"/>

--

1. Familiar syntax; ease of interaction

--

2. *Fast* (e.g., compared to INLA or mgcv*)

--

3. Features (e.g., anisotropy, breakpoints, index standardization)


<!-- advanced stuff to feature: -->

<!-- - time-varying coefficients -->
<!-- - spatially varying coefficients -->
<!-- - PC Matern priors -->
<!-- - smoothers like mgcv -->
<!-- - nice and stable Tweedie -->
<!-- - MLE-MCMC residuals -->
<!-- - nice predict() and prediction data frame -->
<!-- - nice summary() -->
<!-- - nice tidy() -->
<!-- - passing to tmbstan -->
<!-- - wide variety of families -->


<!-- <img src="images/sdmTMB_workflow.png" height = "500px" width="900px" /> -->

<!-- # Preparing data: getting into constant distance coordinates -->

<!-- # Getting into UTMs -->

<!-- Need a projection that preserves constant distance -->

<!-- UTMs work well for regional analyses -->

<!-- Helper function: `sdmTMB::add_utm_columns()` -->

<!-- Internally, guesses at UTM zone and uses the sf package:   -->
<!-- `sf::st_as_sf()`, `sf::st_transform()`, and `sf::st_coordinates()` -->

<!-- Or use the sf or sp packages yourself -->

<!-- # Example of adding UTM columns -->

<!-- d <- data.frame( -->
<!--   lat = c(52.1, 53.4),  -->
<!--   lon = c(-130.0, -131.4) -->
<!-- ) -->
<!-- d <- sdmTMB::add_utm_columns(d, c("lon", "lat")) -->
<!-- d -->

<!-- * Note default `units = "km"` -->
<!-- * Why? Range parameter estimated in units of X and Y -->
<!-- * Should be not too big or small for estimation -->


<!-- --- -->

<!-- # Logistic functions for threshold analyses -->

<!-- cpue ~ logistic(temperature) -->

<!-- df <- data.frame(x = seq(1, 100)) -->
<!-- slope <- 0.1 -->
<!-- df$y <- 3.0 / (1 + exp(-0.1 * (df$x - 50))) -->
<!-- ggplot(df, aes(x, y)) + -->
<!--   geom_line(col = "blue") + -->
<!--   xlab("Temperature") + -->
<!--   ylab("CPUE") + -->
<!--   ggtitle("Logistic function") -->



<!-- # After model fitting -->

<!-- Inspecting, summarizing, predicting, etc. -->

<!-- Covered in examples in next slides. -->

<!-- * `predict()`: `?predict.sdmTMB` -->
<!-- * `residuals()`: `?residuals.sdmTMB` -->
<!-- * `print()` -->
<!-- * `tidy()`: `?tidy.sdmTMB` -->
<!-- * `get_index()` -->
<!-- *  `...` -->

---

# Breakpoint functions for threshold analyses

```{r breakpt, echo=TRUE, eval=FALSE}
cpue ~ breakpt(temperature)
```

```{r make-breakpt, out.width='500px', fig.width=5}
df <- data.frame(x = seq(1, 100))
slope <- 0.1
df$y <- ifelse(df$x < 50, slope * df$x, slope * 50)
ggplot(df, aes(x, y)) +
  geom_line(col = "black") +
  xlab("Temperature") +
  ylab("CPUE") +
  ggtitle("Breakpoint function")
```


---

# Installing sdmTMB

.small[
Currently:

Install a C++ compiler
* e.g., [Rtools](https://cran.r-project.org/bin/windows/Rtools/rtools40.html) on Windows
* e.g., Xcode command line tools on a Mac:  
  `xcode-select --install`
]

```{r, eval=FALSE, echo=TRUE}
# install.packages("remotes")
remotes::install_github("pbs-assess/sdmTMB", 
  dependencies = TRUE)
```

.small[
Should be on CRAN (very?) soon for easier installation.
]

---

# Spatial vs. spatiotemporal fields

* A spatial field can be thought of as a spatial intercept

  * a wiggly spatial process that is constant in time
  
--

* Spatiotemporal variation represents separate fields estimated for each time
  slice (possibly correlated)
  
  * wiggly spatial processes that change through time

--

* Refer to [model description](https://pbs-assess.github.io/sdmTMB/articles/model-description.html) vignette for math notation


# Residuals

.small[
Randomized quantile residuals from Laplace approximation

```{r residuals, eval=FALSE, echo=TRUE}
r <- residuals(fit)
```

Same but MCMC-based with fixed effects at MLE (slower)

```{r mcmc-residuals, eval=FALSE, echo=TRUE}
r <- residuals(fit, type = "mle-mcmc")
```

Simulation-based residuals with the DHARMa package

```{r dharma-residuals, eval=FALSE, echo=TRUE}
simulate(fit, nsim = 300) %>% 
  dharma_residuals(fit)
```

See `?residuals.sdmTMB()`.
]

---

# sdmTMB workflow

1. Prepare data .xsmall[(convert to UTMs, scale covariates, ...)]

2. Construct a mesh

3. Fit the model

4. Inspect the model .xsmall[(and possibly refit the model)]

5. Predict from the model

6. Calculate any derived quantities

---

# sdmTMB workflow

1. Prepare data: .blue[`add_utm_columns()`]

2. Construct a mesh: .blue[`make_mesh()`]

3. Fit the model: .blue[`sdmTMB()`]

4. Inspect the model: .blue[`print()`], .blue[`tidy()`], .blue[`residuals()`]

5. Predict from the model: .blue[`predict()`]

6. Get derived quantities: .blue[`get_index()`], .blue[`get_cog()`]

---

# Constructing a mesh

`make_mesh()` has 2 shortcuts to mesh construction

1. K-means algorithm: used to cluster points (e.g., `n_knots = 100`)

2. Cutoff: minimum allowed distance between vertices (e.g., `cutoff = 10`)
  
Alternatively, build any INLA mesh and supply it to the `mesh` argument in `make_mesh()`

---

# Constructing a mesh

.small[
Size of mesh has the single largest impact on fitting speed

`cutoff` is in units of x and y (minimum triangle size)
]

.small[
```{r make-mesh, echo=TRUE, fig.asp=1, out.width='280px', fig.width=5.5}
d <- data.frame(x = runif(500), y = runif(500))
mesh <- make_mesh(d, xy_cols = c("x", "y"), cutoff = 0.1)
plot(mesh)
```
]



# Visualization with visreg

.small[
Default plot is in link space with partial randomized quantile residuals:


```{r visreg, echo=FALSE, fig.asp=0.6, eval=FALSE}
visreg::visreg(fit, xvar = "depth")
```

]

---

# Visualization with ggeffects

.xsmall[
Fork of ggeffects; pull request will be made soon.

`ggeffects::ggeffect()` also works for marginal effects, but *not* for smoothers.
]

.small[
```{r ggeffects, echo=FALSE, out.width="500px", fig.asp=0.5, eval=FALSE}
ggeffects::ggpredict(fit2, terms = "depth [50:300]") %>% 
  plot()
```
]

---
